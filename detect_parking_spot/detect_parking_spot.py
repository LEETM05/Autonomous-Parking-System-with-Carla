from ultralytics import YOLO
import numpy as np
import json
import math
import argparse
import cv2 # ğŸ’¡ ì¶”ê°€
from PIL import Image, ImageDraw, ImageFont # ğŸ’¡ ì¶”ê°€

# [ìˆ˜ì • ì „] convert_obb_to_four_corners í•¨ìˆ˜ (YOLO OBBëŠ” ì´ë¯¸ ë„¤ ê¼­ì§“ì ì„ ë°˜í™˜í•˜ë¯€ë¡œ í•„ìš” ì—†ì–´ì§)

def draw_obb(image_np, obb_corners, text, color=(0, 0, 255), thickness=2):
    """
    numpy ë°°ì—´ ì´ë¯¸ì§€ì— íšŒì „ëœ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    obb_cornersëŠ” [[x1, y1], [x2, y2], [x3, y3], [x4, y4]] í˜•ì‹ì…ë‹ˆë‹¤.
    """
    points = np.array(obb_corners, dtype=np.int32)
    cv2.polylines(image_np, [points], isClosed=True, color=color, thickness=thickness)

    # í…ìŠ¤íŠ¸ ì¶”ê°€ (PILì„ ì‚¬ìš©í•˜ì—¬ í•œê¸€ ì§€ì› ë° ê¹¨ì§ ë°©ì§€)
    img_pil = Image.fromarray(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    
    # í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œì— í•œê¸€ í°íŠ¸ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆ: NotoSansKR)
    try:
        font = ImageFont.truetype("NotoSansKR-Regular.otf", 18) # ğŸ’¡ í°íŠ¸ ê²½ë¡œì™€ í¬ê¸° ì¡°ì •
    except IOError:
        font = ImageFont.load_default() # í°íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©

    # ë°•ìŠ¤ì˜ ì²« ë²ˆì§¸ ê¼­ì§“ì  ê·¼ì²˜ì— í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜
    text_pos = (int(obb_corners[0][0]), int(obb_corners[0][1] - 25)) # yì¶•ìœ¼ë¡œ 25í”½ì…€ ìœ„ë¡œ ì´ë™
    
    # í…ìŠ¤íŠ¸ ì™¸ê³½ì„  (ì„ ëª…í•˜ê²Œ ë³´ì´ë„ë¡)
    for x_offset in [-1, 1]:
        for y_offset in [-1, 1]:
            draw.text((text_pos[0] + x_offset, text_pos[1] + y_offset), text, font=font, fill=(0,0,0)) # ê²€ì€ìƒ‰ ì™¸ê³½ì„ 
    draw.text(text_pos, text, font=font, fill=color) # ë°•ìŠ¤ ìƒ‰ê¹”ë¡œ ë³¸ë¬¸ í…ìŠ¤íŠ¸

    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)


def main(image_path, model_path, output_json_path, visualize_output_path=None):
    # í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    model = YOLO(model_path)
    
    # ì´ë¯¸ì§€ì—ì„œ ê°ì²´ íƒì§€
    results = model(image_path)
    
    detected_spots = []
    
    # ğŸ’¡ [ì¶”ê°€] ì‹œê°í™”ìš© ì´ë¯¸ì§€ ë¡œë“œ
    img_for_vis = cv2.imread(image_path)
    if img_for_vis is None:
        print(f"Detector: Error loading image for visualization: {image_path}")
        return

    for r in results:
        # OBB ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        if r.obb is not None:
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ í”½ì…€ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•¨)
            # YOLOv8ì˜ r.obb.xyxyxyxyëŠ” ì´ë¯¸ í”½ì…€ ì¢Œí‘œì´ë¯€ë¡œ ë³€í™˜ ë¶ˆí•„ìš”
            img_width, img_height = r.orig_shape[1], r.orig_shape[0]

            for i, obb in enumerate(r.obb):
                # xyxyxyxy: [x1, y1, x2, y2, x3, y3, x4, y4]
                # ì´ ì¢Œí‘œëŠ” ì´ë¯¸ í”½ì…€ ë‹¨ìœ„ì…ë‹ˆë‹¤.
                # numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ reshapeí•˜ì—¬ [[x1,y1], [x2,y2], ... ] í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤.
                obb_corners_flat = obb.xyxyxyxy.cpu().numpy()[0]
                obb_corners = obb_corners_flat.reshape(-1, 2).tolist() # [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                
                confidence = float(obb.conf.cpu().numpy()[0])
                class_id = int(obb.cls.cpu().numpy()[0])
                
                # í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘ (data.yamlì˜ namesì™€ ì¼ì¹˜ì‹œì¼œì•¼ í•©ë‹ˆë‹¤)
                class_name = model.names[class_id] # YOLO ëª¨ë¸ ë‚´ë¶€ì— names ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤.

                detected_spots.append({
                    'confidence': confidence,
                    'corners': obb_corners, # ì´ë¯¸ í”½ì…€ ì¢Œí‘œ
                    'class_name': class_name
                })
                
                # ğŸ’¡ [ì¶”ê°€] ì‹œê°í™”: ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦½ë‹ˆë‹¤.
                text = f"{class_name} {confidence:.1f}"
                img_for_vis = draw_obb(img_for_vis, obb_corners, text)

    # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    detected_spots.sort(key=lambda x: x['confidence'], reverse=True)
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    with open(output_json_path, 'w') as f:
        json.dump(detected_spots, f, indent=4)
        
    print(f"Detector: Found {len(detected_spots)} spots. Results saved to {output_json_path}")

    # ğŸ’¡ [ì¶”ê°€] ì‹œê°í™”ëœ ì´ë¯¸ì§€ ì €ì¥
    if visualize_output_path:
        cv2.imwrite(visualize_output_path, img_for_vis)
        print(f"Detector: Visualized image saved to {visualize_output_path}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--image', type=str, required=True, help='Path to the input image.')
    parser.add_argument('--model', type=str, default='best.pt', help='Path to the trained YOLO model.')
    parser.add_argument('--output_json', type=str, default='result.json', help='Path to the output JSON file.')
    # ğŸ’¡ [ì¶”ê°€] ì‹œê°í™”ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ê²½ë¡œ ì¸ì
    parser.add_argument('--output_vis_img', type=str, default='_detected_parking_spot.png', 
                        help='Path to save the visualized image.')
    args = parser.parse_args()
    
    main(args.image, args.model, args.output_json, args.output_vis_img)